{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.preprocessing import image\n",
    "#from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator,  img_to_array, load_img\n",
    "\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import subprocess\n",
    "import os\n",
    "import pickle\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, merge, Lambda,UpSampling2D, concatenate, Reshape, Dropout,Cropping2D,Activation\n",
    "from keras.models import Model, load_model\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.callbacks import Callback\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.nasnet import NASNetMobile,NASNetLarge\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tao_file_preprocess import make_ok_ng_dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./dataset/ARY_ADJ/0/NG/AI', './dataset/ARY_ADJ/0/OK/AI', './dataset/ARY_ADJ/1/NG/AI', './dataset/ARY_ADJ/1/OK/AI', './dataset/ARY_ADJ/2/NG/AI', './dataset/ARY_ADJ/3/NG/AI', './dataset/ARY_ADJ/3/OK/AI', './dataset/ARY_ADJ/4/AI', './dataset/ARY_ADJ/5/AI', './dataset/ARY_ADJ/6/OK Natural/AI', './dataset/ARY_ADJ/6/OK Artificial/AI', './dataset/ARY_ADJ/7/NG/AI', './dataset/ARY_ADJ/7/OK/AI', './dataset/ARY_ADJ/8/OK/AI']\n",
      "./dataset/ARY_ADJ/4/AI \t 311\n",
      "./dataset/ARY_ADJ/0/OK/AI \t 171\n",
      "./dataset/ARY_ADJ/1/NG/AI \t 423\n",
      "./dataset/ARY_ADJ/6/OK Artificial/AI \t 274\n",
      "./dataset/ARY_ADJ/3/OK/AI \t 301\n",
      "./dataset/ARY_ADJ/5/AI \t 409\n",
      "./dataset/ARY_ADJ/0/NG/AI \t 192\n",
      "./dataset/ARY_ADJ/7/OK/AI \t 418\n",
      "./dataset/ARY_ADJ/2/NG/AI \t 173\n",
      "./dataset/ARY_ADJ/6/OK Natural/AI \t 135\n",
      "./dataset/ARY_ADJ/1/OK/AI \t 404\n",
      "./dataset/ARY_ADJ/3/NG/AI \t 109\n",
      "./dataset/ARY_ADJ/7/NG/AI \t 258\n",
      "./dataset/ARY_ADJ/8/OK/AI \t 253\n",
      "['./dataset/ARY_ADJ/0/OK/AI', './dataset/ARY_ADJ/1/OK/AI', './dataset/ARY_ADJ/3/OK/AI', './dataset/ARY_ADJ/6/OK Natural/AI', './dataset/ARY_ADJ/6/OK Artificial/AI', './dataset/ARY_ADJ/7/OK/AI', './dataset/ARY_ADJ/8/OK/AI']\n",
      "['./dataset/ARY_ADJ/0/NG/AI', './dataset/ARY_ADJ/1/NG/AI', './dataset/ARY_ADJ/2/NG/AI', './dataset/ARY_ADJ/3/NG/AI', './dataset/ARY_ADJ/4/AI', './dataset/ARY_ADJ/5/AI', './dataset/ARY_ADJ/7/NG/AI']\n",
      "\n",
      "\n",
      "{'./dataset/ARY_ADJ/4/AI': '4_NG_', './dataset/ARY_ADJ/0/NG/AI': '0_NG_', './dataset/ARY_ADJ/7/NG/AI': '7_NG_', './dataset/ARY_ADJ/5/AI': '5_NG_', './dataset/ARY_ADJ/3/NG/AI': '3_NG_', './dataset/ARY_ADJ/1/NG/AI': '1_NG_', './dataset/ARY_ADJ/2/NG/AI': '2_NG_'}\n",
      "\n",
      "\n",
      "{'./dataset/ARY_ADJ/0/OK/AI': '0_OK_', './dataset/ARY_ADJ/6/OK Natural/AI': '6_OK_', './dataset/ARY_ADJ/1/OK/AI': '1_OK_', './dataset/ARY_ADJ/3/OK/AI': '3_OK_', './dataset/ARY_ADJ/8/OK/AI': '8_OK_', './dataset/ARY_ADJ/7/OK/AI': '7_OK_', './dataset/ARY_ADJ/6/OK Artificial/AI': '6_OK_'}\n"
     ]
    }
   ],
   "source": [
    "data_path = './dataset/ARY_ADJ/'\n",
    "ok_dir,ok_prefix,ng_dir,ng_prefix= make_ok_ng_dir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_dir_files.pkl','rb') as handle:\n",
    "    \n",
    "    final_dir_files = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./np_data_model/'): \n",
    "    os.makedirs('./np_data_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './np_data_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_train_data(dirs,finale_dir_files):\n",
    "    \n",
    "    final_array =[]\n",
    "\n",
    "   \n",
    "    s = time.time()\n",
    "    for i, dir  in enumerate(dirs):\n",
    "        img_list=[]\n",
    "        print ('current dir=', dir)\n",
    "        \n",
    "        for im in final_dir_files[dir]:\n",
    "            s1 =s\n",
    "\n",
    "\n",
    "            img = load_img(dir+'/'+im, target_size=(224, 224))  # this is a PIL image\n",
    "            x = img_to_array(img)\n",
    "            x = preprocess_input(x)\n",
    "            #print (x.shape)\n",
    "            #x = cv2.cvtColor(y, cv2.COLOR_BGR2RGB)\n",
    "            #x = x/127.5 -1.\n",
    "            img_list.append(x)\n",
    "            #print ('img_list=', len(img_list))\n",
    "        testing_data = np.stack(img_list,axis=0)\n",
    "        #pred = first_prediction(model_1,testing_data)\n",
    "        final_array.append(testing_data)\n",
    "        e = time.time()    \n",
    "        \n",
    "        print ('batch {}, shape {},time = {}'.format(i,len(final_array),round(e -s1 ,4)))\n",
    "        s1=e\n",
    " \n",
    "    final_array = np.concatenate(final_array,axis=0)\n",
    "    print ('train_x_shape',final_array.shape)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    print ('train_x_saved')\n",
    "\n",
    "    e = time.time()\n",
    "    print ('time=', round(e -s ,4))\n",
    "    \n",
    "    return final_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current dir= ./dataset/ARY_ADJ/0/OK/AI\n",
      "batch 0, shape 1,time = 2.7213\n",
      "current dir= ./dataset/ARY_ADJ/1/OK/AI\n",
      "batch 1, shape 2,time = 9.1113\n",
      "current dir= ./dataset/ARY_ADJ/3/OK/AI\n",
      "batch 2, shape 3,time = 13.936\n",
      "current dir= ./dataset/ARY_ADJ/6/OK Natural/AI\n",
      "batch 3, shape 4,time = 16.066\n",
      "current dir= ./dataset/ARY_ADJ/6/OK Artificial/AI\n",
      "batch 4, shape 5,time = 19.8781\n",
      "current dir= ./dataset/ARY_ADJ/7/OK/AI\n",
      "batch 5, shape 6,time = 26.6048\n",
      "current dir= ./dataset/ARY_ADJ/8/OK/AI\n",
      "batch 6, shape 7,time = 30.6273\n",
      "train_x_shape (1950, 224, 224, 3)\n",
      "train_x_saved\n",
      "time= 30.7792\n",
      "ok image shape= (1950, 224, 224, 3) ok_label =  (1950, 1) ok image data completed\n"
     ]
    }
   ],
   "source": [
    "ok_train= make_train_data(ok_dir,final_dir_files)\n",
    "np.save(save_dir +'train_x_ok_just_image'+'.npy',ok_train)\n",
    "ok_label = np.zeros((ok_train.shape[0],1))\n",
    "print ('ok image shape=', ok_train.shape, 'ok_label = ', ok_label.shape, 'ok image data completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current dir= ./dataset/ARY_ADJ/0/NG/AI\n",
      "batch 0, shape 1,time = 3.0459\n",
      "current dir= ./dataset/ARY_ADJ/1/NG/AI\n",
      "batch 1, shape 2,time = 9.7276\n",
      "current dir= ./dataset/ARY_ADJ/2/NG/AI\n",
      "batch 2, shape 3,time = 12.5216\n",
      "current dir= ./dataset/ARY_ADJ/3/NG/AI\n",
      "batch 3, shape 4,time = 14.2625\n",
      "current dir= ./dataset/ARY_ADJ/4/AI\n",
      "batch 4, shape 5,time = 19.2918\n",
      "current dir= ./dataset/ARY_ADJ/5/AI\n",
      "batch 5, shape 6,time = 25.8771\n",
      "current dir= ./dataset/ARY_ADJ/7/NG/AI\n",
      "batch 6, shape 7,time = 30.0645\n",
      "train_x_shape (1869, 224, 224, 3)\n",
      "train_x_saved\n",
      "time= 30.2116\n",
      "ng image shape= (1869, 224, 224, 3) ng_label =  (1869, 1) ng image data completed\n"
     ]
    }
   ],
   "source": [
    "ng_train= make_train_data(ng_dir,final_dir_files)\n",
    "np.save(save_dir +'train_x_ng_just_image'+'.npy',ng_train)\n",
    "ng_label = np.ones((ng_train.shape[0],1))\n",
    "print ('ng image shape=', ng_train.shape, 'ng_label = ', ng_label.shape, 'ng image data completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_train_x shape (3819, 224, 224, 3) saved\n",
      "final_train_y shape (3819, 1) saved\n"
     ]
    }
   ],
   "source": [
    "final_train_x = np.concatenate([ok_train,ng_train],axis=0)\n",
    "np.save(save_dir+'final_train_x_just_image.npy',final_train_x)\n",
    "print ('final_train_x shape', final_train_x.shape, 'saved')\n",
    "final_train_y = np.concatenate([ok_label,ng_label],axis=0)\n",
    "\n",
    "np.save(save_dir+'final_train_y_just_image.npy',final_train_y)\n",
    "print ('final_train_y shape', final_train_y.shape, 'saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-14 00:15:20.083233\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
